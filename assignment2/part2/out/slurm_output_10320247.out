Running experiment on cifar10 with random_patch and prompt size 30
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=12, epochs=20, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=30, text_prompt_template='This is a photo of a {}', visualize_prompt=True, root='/scratch/lcur0640', dataset='cifar10', image_size=224, test_noise=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_30_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume=None, evaluate=False, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_30_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /scratch/lcur0640/cifar-10-python.tar.gz
  0%|          | 0/170498071 [00:00<?, ?it/s]  0%|          | 65536/170498071 [00:00<08:44, 324707.52it/s]  0%|          | 131072/170498071 [00:00<08:20, 340334.43it/s]  0%|          | 196608/170498071 [00:00<06:32, 433778.40it/s]  0%|          | 262144/170498071 [00:00<05:40, 499740.45it/s]  0%|          | 458752/170498071 [00:00<03:01, 934801.72it/s]  0%|          | 753664/170498071 [00:00<01:51, 1526838.22it/s]  1%|          | 1441792/170498071 [00:00<00:54, 3104538.96it/s]  2%|▏         | 2752512/170498071 [00:00<00:27, 6078739.17it/s]  3%|▎         | 4358144/170498071 [00:01<00:18, 9052808.08it/s]  4%|▎         | 6160384/170498071 [00:01<00:14, 11702245.32it/s]  5%|▍         | 8093696/170498071 [00:01<00:11, 13950296.95it/s]  6%|▌         | 10059776/170498071 [00:01<00:10, 15603052.39it/s]  7%|▋         | 12156928/170498071 [00:01<00:09, 17104993.77it/s]  8%|▊         | 14286848/170498071 [00:01<00:08, 18295117.30it/s] 10%|▉         | 16515072/170498071 [00:01<00:07, 19398052.68it/s] 11%|█         | 18776064/170498071 [00:01<00:07, 20328849.46it/s] 12%|█▏        | 21168128/170498071 [00:01<00:06, 21382176.01it/s] 14%|█▍        | 23592960/170498071 [00:02<00:06, 22146225.56it/s] 15%|█▌        | 26116096/170498071 [00:02<00:06, 23064686.40it/s] 17%|█▋        | 28704768/170498071 [00:02<00:05, 23878215.91it/s] 18%|█▊        | 31457280/170498071 [00:02<00:05, 24858338.26it/s] 20%|██        | 34275328/170498071 [00:02<00:05, 25845945.96it/s] 22%|██▏       | 37060608/170498071 [00:02<00:05, 26390317.56it/s] 24%|██▎       | 40075264/170498071 [00:02<00:04, 27407291.46it/s] 25%|██▌       | 43155456/170498071 [00:02<00:04, 28301480.60it/s] 27%|██▋       | 46301184/170498071 [00:02<00:04, 29071078.40it/s] 29%|██▉       | 49512448/170498071 [00:02<00:04, 29764476.44it/s] 31%|███       | 52756480/170498071 [00:03<00:03, 30553961.35it/s] 33%|███▎      | 55869440/170498071 [00:03<00:03, 30654746.01it/s] 35%|███▍      | 59080704/170498071 [00:03<00:03, 30471659.46it/s] 37%|███▋      | 62291968/170498071 [00:03<00:03, 30671628.09it/s] 38%|███▊      | 65404928/170498071 [00:03<00:03, 30764147.49it/s] 40%|████      | 68485120/170498071 [00:03<00:03, 30348271.62it/s] 42%|████▏     | 71532544/170498071 [00:03<00:03, 29723523.19it/s] 44%|████▎     | 74514432/170498071 [00:03<00:03, 29267417.97it/s] 45%|████▌     | 77463552/170498071 [00:03<00:03, 28840110.53it/s] 47%|████▋     | 80379904/170498071 [00:03<00:03, 28460138.13it/s] 49%|████▉     | 83230720/170498071 [00:04<00:03, 28137168.00it/s] 50%|█████     | 86048768/170498071 [00:04<00:03, 27878906.84it/s] 52%|█████▏    | 88866816/170498071 [00:04<00:02, 27741024.57it/s] 54%|█████▍    | 91750400/170498071 [00:04<00:02, 27797588.16it/s] 56%|█████▌    | 94732288/170498071 [00:04<00:02, 27669652.04it/s] 57%|█████▋    | 97681408/170498071 [00:04<00:02, 27740348.89it/s] 59%|█████▉    | 100630528/170498071 [00:04<00:02, 27791946.14it/s] 61%|██████    | 103677952/170498071 [00:04<00:02, 27886900.68it/s] 63%|██████▎   | 106659840/170498071 [00:04<00:02, 27948091.37it/s] 64%|██████▍   | 109707264/170498071 [00:05<00:02, 28033828.96it/s] 66%|██████▌   | 112754688/170498071 [00:05<00:02, 27917885.97it/s] 68%|██████▊   | 115802112/170498071 [00:05<00:01, 27870201.26it/s] 70%|██████▉   | 118816768/170498071 [00:05<00:01, 27894240.60it/s] 71%|███████▏  | 121864192/170498071 [00:05<00:01, 27829220.14it/s] 73%|███████▎  | 124813312/170498071 [00:05<00:01, 27823358.90it/s] 75%|███████▍  | 127827968/170498071 [00:05<00:01, 27835720.73it/s] 77%|███████▋  | 130842624/170498071 [00:05<00:01, 27926493.89it/s] 79%|███████▊  | 133890048/170498071 [00:05<00:01, 28017793.50it/s] 80%|████████  | 136937472/170498071 [00:05<00:01, 27976326.29it/s] 82%|████████▏ | 139952128/170498071 [00:06<00:01, 27995259.97it/s] 84%|████████▍ | 142901248/170498071 [00:06<00:00, 28039153.02it/s] 86%|████████▌ | 145948672/170498071 [00:06<00:00, 28239850.16it/s] 87%|████████▋ | 149061632/170498071 [00:06<00:00, 28937420.97it/s] 89%|████████▉ | 152272896/170498071 [00:06<00:00, 29620198.90it/s] 91%|█████████ | 155516928/170498071 [00:06<00:00, 30435617.93it/s] 93%|█████████▎| 158662656/170498071 [00:06<00:00, 30641798.54it/s] 95%|█████████▍| 161906688/170498071 [00:06<00:00, 30898633.68it/s] 97%|█████████▋| 165183488/170498071 [00:06<00:00, 31189364.21it/s] 99%|█████████▉| 168427520/170498071 [00:07<00:00, 31554297.88it/s]100%|██████████| 170498071/170498071 [00:07<00:00, 24048330.03it/s]
/home/lcur0640/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Extracting /scratch/lcur0640/cifar-10-python.tar.gz to /scratch/lcur0640
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
  0%|                                               | 0.00/338M [00:00<?, ?iB/s]  1%|▎                                     | 3.19M/338M [00:00<00:10, 32.7MiB/s]  6%|██▍                                    | 21.1M/338M [00:00<00:02, 123MiB/s] 13%|████▉                                  | 42.4M/338M [00:00<00:01, 168MiB/s] 19%|███████▍                               | 64.9M/338M [00:00<00:01, 195MiB/s] 26%|██████████▏                            | 88.1M/338M [00:00<00:01, 212MiB/s] 32%|████████████▉                           | 109M/338M [00:00<00:01, 216MiB/s] 40%|███████████████▊                        | 133M/338M [00:00<00:00, 228MiB/s] 46%|██████████████████▌                     | 157M/338M [00:00<00:00, 233MiB/s] 53%|█████████████████████▏                  | 179M/338M [00:00<00:00, 222MiB/s] 59%|███████████████████████▋                | 200M/338M [00:01<00:00, 215MiB/s] 65%|██████████████████████████▏             | 221M/338M [00:01<00:00, 212MiB/s] 71%|████████████████████████████▌           | 241M/338M [00:01<00:00, 210MiB/s] 77%|██████████████████████████████▉         | 261M/338M [00:01<00:00, 209MiB/s] 83%|█████████████████████████████████▎      | 281M/338M [00:01<00:00, 210MiB/s] 89%|███████████████████████████████████▋    | 302M/338M [00:01<00:00, 211MiB/s] 95%|██████████████████████████████████████▏ | 322M/338M [00:01<00:00, 212MiB/s]100%|████████████████████████████████████████| 338M/338M [00:01<00:00, 205MiB/s]
List of prompts:
['This is a photo of a airplane',
 'This is a photo of a automobile',
 'This is a photo of a bird',
 'This is a photo of a cat',
 'This is a photo of a deer',
 'This is a photo of a dog',
 'This is a photo of a frog',
 'This is a photo of a horse',
 'This is a photo of a ship',
 'This is a photo of a truck']
Traceback (most recent call last):
  File "/home/lcur0640/repos/DeepLearning1_UvA_22/assignment2/part2/.//main.py", line 150, in <module>
    main()
  File "/home/lcur0640/repos/DeepLearning1_UvA_22/assignment2/part2/.//main.py", line 139, in main
    learn = Learner(args)
  File "/home/lcur0640/repos/DeepLearning1_UvA_22/assignment2/part2/learner.py", line 56, in __init__
    self.vpt = CustomCLIP(args, self.test_dataset, template=PROMPT_TEMPLATE)
  File "/home/lcur0640/repos/DeepLearning1_UvA_22/assignment2/part2/vpt_model.py", line 106, in __init__
    self.visualize_prompt(args.method)
  File "/home/lcur0640/.conda/envs/dl2022/lib/python3.10/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/lcur0640/repos/DeepLearning1_UvA_22/assignment2/part2/vpt_model.py", line 158, in visualize_prompt
    prompted_img = self.prompt_learner(fake_img)[0].cpu()
  File "/home/lcur0640/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/lcur0640/repos/DeepLearning1_UvA_22/assignment2/part2/vp.py", line 190, in forward
    origin = torch.randint(x.shape[2] - patch_size)
TypeError: randint() received an invalid combination of arguments - got (int), but expected one of:
 * (int high, tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)
 * (int high, tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)
 * (int low, int high, tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)
 * (int low, int high, tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)

